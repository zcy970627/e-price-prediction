{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import math,datetime\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "#from datetime import datetime\n",
    "\n",
    "df=pd.read_csv('historical_data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = df.corr()\n",
    "with open('corr.npy', 'wb') as f:\n",
    "    np.save(f, corr_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.BufferedWriter name='corr.npy'>"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[42.34],\n",
       "       [38.89],\n",
       "       [38.82],\n",
       "       ...,\n",
       "       [97.02],\n",
       "       [96.01],\n",
       "       [84.36]])"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data = df.filter(['elec_price'])\n",
    "\n",
    "data = df.filter(['elec_price',\n",
    " \n",
    " ])\n",
    "\n",
    "dataset = data.values\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_len = math.ceil( len(dataset) * .8 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler =StandardScaler()\n",
    "\n",
    "scaled_data = scaler.fit_transform(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Create the scaled training data set\n",
    "train_data = scaled_data[0:training_data_len , :]\n",
    "#Split the data into x_train and y_train data sets\n",
    "x_trainl = []\n",
    "y_trainl = []\n",
    "\n",
    "#hourly prediction\n",
    "training_window = 24\n",
    "prediction_time=1\n",
    "#daily prediction\n",
    "# training_window = 24*7\n",
    "# prediction_time=24*1\n",
    "#weekly prediction\n",
    "# training_window = 24*7*3\n",
    "# prediction_time=24*7\n",
    "\n",
    "for i in range(training_window, len(train_data)-prediction_time):\n",
    "    x_trainl.append(train_data[i-training_window:i, 0])\n",
    "    y_trainl.append(train_data[i:i+prediction_time, 0])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert the x_train and y_train to numpy arrays\n",
    "x_trainl, y_trainl = np.array(x_trainl), np.array(y_trainl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21595, 24, 1)"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reshape the data\n",
    "x_trainl = np.reshape(x_trainl, (x_trainl.shape[0], x_trainl.shape[1], 1))\n",
    "x_trainl.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_24 (LSTM)               (None, 24, 50)            10400     \n",
      "_________________________________________________________________\n",
      "lstm_25 (LSTM)               (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 25)                1275      \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 1)                 26        \n",
      "=================================================================\n",
      "Total params: 31,901\n",
      "Trainable params: 31,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import RepeatVector\n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(50, return_sequences=True, input_shape= (x_trainl.shape[1], 1)))\n",
    "model.add(LSTM(50, return_sequences= False))\n",
    "model.add(Dense(25))\n",
    "model.add(Dense(y_trainl.shape[1]))\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile the model\n",
    "model.compile(optimizer='adam',loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "675/675 [==============================] - 14s 16ms/step - loss: 0.1049\n",
      "Epoch 2/15\n",
      "675/675 [==============================] - 11s 16ms/step - loss: 0.0483\n",
      "Epoch 3/15\n",
      "675/675 [==============================] - 11s 16ms/step - loss: 0.0460 0s\n",
      "Epoch 4/15\n",
      "675/675 [==============================] - 14s 21ms/step - loss: 0.0451\n",
      "Epoch 5/15\n",
      "675/675 [==============================] - 17s 25ms/step - loss: 0.0450 0s - los\n",
      "Epoch 6/15\n",
      "675/675 [==============================] - 17s 25ms/step - loss: 0.0435\n",
      "Epoch 7/15\n",
      "675/675 [==============================] - 15s 23ms/step - loss: 0.0435\n",
      "Epoch 8/15\n",
      "675/675 [==============================] - 13s 19ms/step - loss: 0.0435\n",
      "Epoch 9/15\n",
      "675/675 [==============================] - 14s 21ms/step - loss: 0.0431\n",
      "Epoch 10/15\n",
      "675/675 [==============================] - 13s 19ms/step - loss: 0.0424\n",
      "Epoch 11/15\n",
      "675/675 [==============================] - 12s 18ms/step - loss: 0.0421\n",
      "Epoch 12/15\n",
      "675/675 [==============================] - 13s 19ms/step - loss: 0.0423\n",
      "Epoch 13/15\n",
      "675/675 [==============================] - 16s 24ms/step - loss: 0.0415\n",
      "Epoch 14/15\n",
      "675/675 [==============================] - 14s 21ms/step - loss: 0.0411\n",
      "Epoch 15/15\n",
      "675/675 [==============================] - 14s 20ms/step - loss: 0.0407 0s - \n"
     ]
    }
   ],
   "source": [
    "#Train the model\n",
    "lstm_start = time.time()\n",
    "\n",
    "history = model.fit(x_trainl, y_trainl, epochs=15, batch_size=32)\n",
    "lstm_end = time.time()\n",
    "\n",
    "total_lstm = lstm_end - lstm_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"uni_model_1week.h5\")\n",
    "import pickle\n",
    "scalerfile = 'scalerweek.sav'\n",
    "pickle.dump(scaler, open(scalerfile, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import pickle\n",
    "model_uni_day = load_model('multi_model_1hour.h5')\n",
    "scalerfile = 'scalerhour.sav'\n",
    "scalerimported = pickle.load(open(scalerfile, 'rb'))\n",
    "\n",
    "predictions_uni = model_uni_day.predict(X_test[:,:,0:1])\n",
    "\n",
    "predictions_uni = scalerimported.inverse_transform(predictions_uni)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5404, 24, 1)\n",
      "(5404, 24, 1)\n",
      "(5404, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[44.967678],\n",
       "       [40.439262],\n",
       "       [34.168316],\n",
       "       ...,\n",
       "       [84.28418 ],\n",
       "       [82.13445 ],\n",
       "       [81.72872 ]], dtype=float32)"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create the testing data set\n",
    "#Create a new array containing scaled values from index 1543 to 2002 \n",
    "test_data = scaled_data[training_data_len - training_window: , :]\n",
    "#Create the data sets x_test and y_test\n",
    "x_testl = []\n",
    "y_testl = dataset[training_data_len:, :]\n",
    "for i in range(training_window, len(test_data)):\n",
    "    x_testl.append(test_data[i-training_window:i, :])\n",
    "\n",
    "#Convert the data to a numpy array\n",
    "x_testl = np.array(x_testl)\n",
    "print(x_testl.shape)\n",
    "#Reshape the data\n",
    "x_testl = np.reshape(x_testl, (x_testl.shape[0], x_testl.shape[1], 1 ))\n",
    "print(x_testl.shape)\n",
    "#Get the models predicted price values \n",
    "#predictionsl = model_uni_day .predict(x_testl)\n",
    "# print(print(x_testl[0:1].shape))\n",
    "# data_csv = pd.read_csv(\"historical_data.csv\")\n",
    "# data_list=list(data_csv)\n",
    "# data_list= data_list[-1:]+ data_list[6:-1]\n",
    "# data_for_prediction=data_csv[data_list[0:1]][-24*7*3:]\n",
    "# data_for_prediction = np.expand_dims(data_for_prediction, axis=0)\n",
    "predictionsl = model.predict(x_testl)\n",
    "predictionsl = scaler.inverse_transform(predictionsl)\n",
    "print(predictionsl.shape)\n",
    "predictionsl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictionsl=scaler.inverse_transform(x_testl[0,:])\n",
    "#y_testl = dataset[-24*7:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.650453696891265"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get the root mean squared error (RMSE)\n",
    "rmse=np.sqrt(np.mean(((predictionsl - y_testl)**2)))\n",
    "rmse"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
